{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2i9izeG76od"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrzE6YiQsRUz"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOQYJzBG3PxM",
        "outputId": "dc470909-d1be-4046-dc51-b8e2218cb248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of lines: 49562\n"
          ]
        }
      ],
      "source": [
        "filename = '/content/shakespeare_data.txt'\n",
        "lines = []\n",
        "counter = 0\n",
        "\n",
        "with open(filename) as files:\n",
        "    for line in files:\n",
        "        pure_line = line.strip()\n",
        "\n",
        "        if pure_line:\n",
        "            lines.append(pure_line)\n",
        "\n",
        "n_lines = len(lines)\n",
        "print(f\"Number of lines: {n_lines}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiEx7Uc44nSe",
        "outputId": "fe91d065-936d-496f-f94f-5c26d0bc081f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BENVOLIO\tHere were the servants of your adversary,\n",
            "And yours, close fighting ere I did approach:\n",
            "I drew to part them: in the instant came\n",
            "The fiery Tybalt, with his sword prepared,\n",
            "Which, as he breathed defiance to my ears,\n",
            "He swung about his head and cut the winds,\n",
            "Who nothing hurt withal hiss'd him in scorn:\n",
            "While we were interchanging thrusts and blows,\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\".join(lines[506:514]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2_hh7OY48Pa",
        "outputId": "6655489d-cc7c-44da-c6e7-fe63746d87e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81 unique characters\n",
            "[UNK]  \t \n",
            "   ! & ' ( ) , - . 0 1 2 3 4 5 6 7 8 9 : ; ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z [ ] a b c d e f g h i j k l m n o p q r s t u v w x y z |\n"
          ]
        }
      ],
      "source": [
        "text = \"\\n\".join(lines)\n",
        "vocab = sorted(set(text))\n",
        "vocab.insert(0,\"[UNK]\")\n",
        "vocab.insert(1,\"\")\n",
        "print(f'{len(vocab)} unique characters')\n",
        "print(\" \".join(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owxphlna5s6u",
        "outputId": "69daceb3-8987-43a2-aac7-28c742603e20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['H', 'e', 'l', 'l', 'o', ' ', 'w', 'o', 'r', 'l', 'd', '!']\n"
          ]
        }
      ],
      "source": [
        "line = \"Hello world!\"\n",
        "chars = list(line)\n",
        "print(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD2yflPR5zYH",
        "outputId": "a11a1e5c-028f-4889-a88e-a13e2b94c2f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54\n",
            "58\n",
            "62\n",
            "68\n",
            "74\n",
            "4\n",
            "15\n",
            "16\n"
          ]
        }
      ],
      "source": [
        "print(vocab.index('a'))\n",
        "print(vocab.index('e'))\n",
        "print(vocab.index('i'))\n",
        "print(vocab.index('o'))\n",
        "print(vocab.index('u'))\n",
        "print(vocab.index(' '))\n",
        "print(vocab.index('2'))\n",
        "print(vocab.index('3'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.index(\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKnrsbgBzaB4",
        "outputId": "bd83b802-23d3-4b40-85e7-8f4b459596ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9NoSzcahd6B",
        "outputId": "3ee39b76-c6af-4f4e-9875-0c19356eb7ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wma7nXv-76BN",
        "outputId": "261b4bc5-e055-4941-8e3a-2395861f7d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training lines: 48562\n",
            "Number of validation lines: 1000\n"
          ]
        }
      ],
      "source": [
        "train_lines = lines[:-1000] # Leave the rest for training\n",
        "eval_lines = lines[-1000:] # Create a holdout validation set\n",
        "\n",
        "print(f\"Number of training lines: {len(train_lines)}\")\n",
        "print(f\"Number of validation lines: {len(eval_lines)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVG8qIOUqZZ6",
        "outputId": "d9e952a6-53ba-4e2c-8ad1-05a0e8dd7d32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "maxx = 0\n",
        "for line in train_lines:\n",
        "  maxx = max(maxx , len(line))\n",
        "\n",
        "for line in eval_lines:\n",
        "  maxx = max(maxx , len(line))\n",
        "maxx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FgTt_BmikE4Q",
        "outputId": "84806b73-0505-4535-f8c8-899d15b3bae9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"A LOVER'S COMPLAINT\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_lines[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d1vaRbFunUyQ",
        "outputId": "2854df82-c2c2-42b5-ead9-4e4b590ba2f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'FROM off a hill whose concave womb reworded'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_lines[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6-MeUKJn9aU",
        "outputId": "51ff0a0b-9066-4e5d-89e3-b8c78cbebd8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48562"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(train_lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxKPCCagoYej",
        "outputId": "19a83344-ad81-4654-d7bd-a71ba0cb8340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "[26, 4, 37, 40, 47, 30, 43, 7, 44, 4, 28, 40, 38, 41, 37, 26, 34, 39, 45]\n"
          ]
        }
      ],
      "source": [
        "line = train_lines[0]\n",
        "print(type(line))\n",
        "chartoids = [vocab.index(i) for i in line]\n",
        "print(chartoids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4q-YiPfbpsW2"
      },
      "outputs": [],
      "source": [
        "def padding(text,max_length=85):\n",
        "  diff = max_length - len(text)\n",
        "  text = text + ([0]*diff)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABbc16jajlE6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        line = self.data[idx]\n",
        "        chartoids = [vocab.index(char) for char in line]\n",
        "        padtext = padding(chartoids)\n",
        "        input_ids = torch.tensor(padtext,dtype=torch.long)\n",
        "        inputs = input_ids[:-1]\n",
        "        target = input_ids[1:]\n",
        "        return inputs,target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uE1Ndv5mp6Yb"
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset(train_lines)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DvuwwS9qFAk",
        "outputId": "83e2eb99-b4bf-420c-a32b-c8103a4cde41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[61, 58, 65, 66, 58, 57,  4, 66, 74, 72, 73,  4, 74, 69, 68, 67,  4, 54,\n",
              "           4, 76, 54, 71, 71, 54, 67, 73, 58, 57,  4, 67, 58, 58, 57,  4, 60, 62,\n",
              "          75, 58,  4, 61, 62, 66,  4, 54,  4, 55, 58, 73, 73, 58, 71,  0,  0,  0,\n",
              "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [45, 61, 58,  4, 64, 62, 67, 60,  4, 72, 61, 54, 65, 65,  4, 61, 54, 75,\n",
              "          58,  4, 66, 78,  4, 72, 58, 71, 75, 62, 56, 58, 23,  4, 55, 74, 73,  4,\n",
              "          66, 78,  4, 69, 71, 54, 78, 58, 71, 72,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]),\n",
              " tensor([[58, 65, 66, 58, 57,  4, 66, 74, 72, 73,  4, 74, 69, 68, 67,  4, 54,  4,\n",
              "          76, 54, 71, 71, 54, 67, 73, 58, 57,  4, 67, 58, 58, 57,  4, 60, 62, 75,\n",
              "          58,  4, 61, 62, 66,  4, 54,  4, 55, 58, 73, 73, 58, 71,  0,  0,  0,  0,\n",
              "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [61, 58,  4, 64, 62, 67, 60,  4, 72, 61, 54, 65, 65,  4, 61, 54, 75, 58,\n",
              "           4, 66, 78,  4, 72, 58, 71, 75, 62, 56, 58, 23,  4, 55, 74, 73,  4, 66,\n",
              "          78,  4, 69, 71, 54, 78, 58, 71, 72,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "next(iter(dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRvrwxRyBEdK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class GRULM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size=256, embedding_dim=256, rnn_units=128):\n",
        "        super(GRULM, self).__init__()\n",
        "\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, rnn_units, batch_first=True)\n",
        "        self.dense = nn.Linear(rnn_units, vocab_size)\n",
        "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "\n",
        "    def forward(self, inputs, states=None, return_state=False):\n",
        "        x = self.embedding(inputs)\n",
        "        if states is None:\n",
        "            states = torch.zeros(1, inputs.size(0), self.gru.hidden_size).to(device)\n",
        "        x, states = self.gru(x, states)\n",
        "        x = self.dense(x)\n",
        "        x = self.log_softmax(x)\n",
        "        if return_state:\n",
        "            return x, states\n",
        "        else:\n",
        "            return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rn45BUdorUIk"
      },
      "outputs": [],
      "source": [
        "\n",
        "vocab_size = 82\n",
        "\n",
        "embedding_dim = 256\n",
        "\n",
        "rnn_units = 512\n",
        "\n",
        "model = GRULM(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units = rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mPQ44vnrqhq"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr= 0.00125)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGrDonXcsWuZ",
        "outputId": "3085d8ed-d039-4351-e6fb-30a73b86796e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, Loss: 0.15330572426319122\n",
            "Epoch 2/15, Loss: 0.7431403398513794\n",
            "Epoch 3/15, Loss: 0.5682281255722046\n",
            "Epoch 4/15, Loss: 0.6760185956954956\n",
            "Epoch 5/15, Loss: 0.6278946995735168\n",
            "Epoch 6/15, Loss: 0.7835381031036377\n",
            "Epoch 7/15, Loss: 0.11920179426670074\n",
            "Epoch 8/15, Loss: 0.6999744772911072\n",
            "Epoch 9/15, Loss: 0.3609185814857483\n",
            "Epoch 10/15, Loss: 0.7994700074195862\n",
            "Epoch 11/15, Loss: 0.5642611384391785\n",
            "Epoch 12/15, Loss: 0.9430555701255798\n",
            "Epoch 13/15, Loss: 0.7064498662948608\n",
            "Epoch 14/15, Loss: 0.6940537691116333\n",
            "Epoch 15/15, Loss: 0.8866020441055298\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "\n",
        "data_loader = dataloader\n",
        "\n",
        "model.train()\n",
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, targets in data_loader:\n",
        "\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        outputs = outputs.view(-1, model.dense.out_features)\n",
        "        targets = targets.view(-1)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKFv4rfQsq4j"
      },
      "outputs": [],
      "source": [
        "def log_perplexity(preds, target):\n",
        "\n",
        "    PADDING_ID = 1\n",
        "\n",
        "    log_p = torch.sum(preds * F.one_hot(target, num_classes=preds.size(-1)), dim=-1).float()\n",
        "    non_pad = 1.0 - torch.eq(target, PADDING_ID).float()\n",
        "    log_p = log_p * non_pad\n",
        "    log_ppx = torch.sum(log_p, dim=1) / torch.sum(non_pad, dim=1)\n",
        "    log_ppx = torch.mean(log_ppx)\n",
        "\n",
        "\n",
        "    return -log_ppx.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def evaluate(model, test_loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            outputs = outputs.view(-1, model.dense.out_features)\n",
        "            targets = targets.view(-1)\n",
        "\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    avg_loss = test_loss / len(test_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "model.to(device)\n",
        "test_loader = DataLoader(CustomDataset(eval_lines), batch_size=64, shuffle=False)\n",
        "avg_loss, accuracy = evaluate(model, test_loader, loss_fn, device)\n",
        "print(f'Average Test Loss: {avg_loss}, Test Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr8GjwTWtZnX",
        "outputId": "8d7802cb-57be-4bc2-d26f-d0520eff22aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Test Loss: 0.6056719660758972, Test Accuracy: 0.8100595238095238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def temperature_random_sampling(log_probs, temperature=1.0):\n",
        "\n",
        "    u = torch.rand(log_probs.size()).clamp(min=1e-6, max=1.0 - 1e-6).to(device)\n",
        "\n",
        "    g = -torch.log(-torch.log(u)).to(device)\n",
        "\n",
        "    return torch.argmax(log_probs + g * temperature, dim=-1).item()\n"
      ],
      "metadata": {
        "id": "OvGyM0FprsE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids, vocab):\n",
        "\n",
        "    id_to_char = {i: char for i, char in enumerate(vocab)}\n",
        "    #print(ids)\n",
        "    chars = [id_to_char[id] for id in ids]\n",
        "    return ''.join(chars)\n"
      ],
      "metadata": {
        "id": "mnsSTEJnyQaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class GenerativeModel(nn.Module):\n",
        "    def __init__(self, model, vocab, temperature=0.1):\n",
        "\n",
        "        super(GenerativeModel, self).__init__()\n",
        "        self.temperature = temperature\n",
        "        self.model = model\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def generate_one_step(self, inputs, states=None):\n",
        "\n",
        "        inputs = [vocab.index(char) for char in inputs]\n",
        "\n",
        "        input_ids = torch.tensor(inputs,dtype=torch.long).to(device)\n",
        "        input_ids = input_ids.unsqueeze(0)\n",
        "\n",
        "        predicted_logits, states = self.model(input_ids,states,True)\n",
        "        predicted_logits = predicted_logits[0, -1, :]\n",
        "        #print(\"last : \" , torch.argmax(predicted_logits).item())\n",
        "\n",
        "        predicted_ids = temperature_random_sampling(predicted_logits, self.temperature)\n",
        "        #print(\"ids : \" , predicted_ids)\n",
        "        predicted_chars = text_from_ids([predicted_ids], self.vocab)\n",
        "        #print(\"predict : \" , predicted_chars)\n",
        "\n",
        "        return predicted_chars, states\n",
        "\n",
        "    def generate_n_chars(self, num_chars, prefix):\n",
        "\n",
        "        states = None\n",
        "        next_char = list(prefix)\n",
        "        #print(next_char)\n",
        "        result = []+next_char\n",
        "        for n in range(num_chars):\n",
        "            next_char, states = self.generate_one_step(next_char, states=states)\n",
        "            result.append(next_char)\n",
        "\n",
        "        return ''.join(result)\n"
      ],
      "metadata": {
        "id": "gUiuyRR9wLAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(272)\n",
        "gen = GenerativeModel(model, vocab, temperature=0.1)\n",
        "\n",
        "#print(gen.generate_one_step('i'))\n",
        "print(gen.generate_n_chars(3, \"i love y\"), '\\n\\n' + '_'*80)\n",
        "#print(gen.generate_n_chars(30, \"i wan to fuck\"), '\\n\\n' + '_'*80)\n",
        "#print(gen.generate_n_chars(32, \"KING\"), '\\n\\n' + '_'*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkIHXQulyZ7E",
        "outputId": "91d1acbe-88c8-4cf8-c844-4b19bdbd2235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i love your \n",
            "\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qVYeqMqePFl_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}